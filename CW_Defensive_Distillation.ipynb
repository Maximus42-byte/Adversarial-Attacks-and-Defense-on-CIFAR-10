{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "cB8T-Dq2pu9r"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Name: Mahdi Saieedi**\n",
        "\n",
        "**Student Number: 401207254**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mhpSyUYiXKug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, you start by loading a trained Resnet model on CIFAR10 dataset. Then, you try to attack it with an $L_{2}$ C&W attack. Next, you work to make this model better at defending using defensive distillation, and test it against two different modes of $L_{2}$ C&W attacks again.\n",
        "\n",
        "It is recommended to use google colab to do this homework. You can connect to your drive using the code below to use it to save and load your trained models:"
      ],
      "metadata": {
        "id": "K2djqmnzUe7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3UxYLgBTS2yC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cca0dd7-d626-44c5-a4cb-039fe6981367"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load CIFAR10 data"
      ],
      "metadata": {
        "id": "V-17Vzi99P3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.utils\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet18\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "4DQBtUQLudCD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "########################## Problem 1 (2  points) ###############################\n",
        "# todo: Define your data loaders for training and testing                      #\n",
        "################################################################################\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define your data loaders for training and testing\n",
        "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "################################ End ###########################################\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "foD6o3tlum1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d22fb918-b5c1-49ae-afa7-62f546d427f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 77126813.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model set-up"
      ],
      "metadata": {
        "id": "kXdawVZoGfJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class resnet(nn.Module):\n",
        "  def __init__(self, num_cls, T=1):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        *list(resnet18(weights=None).children())[:-2])\n",
        "\n",
        "    self.fc = nn.Linear(512, num_cls)\n",
        "    self.temp = T\n",
        "\n",
        "  def forward(self, x, T=None):\n",
        "    if T is None:\n",
        "      T = self.temp\n",
        "    x = self.conv(x)\n",
        "    x = torch.flatten(x, start_dim=1)\n",
        "    logits = self.fc(x)\n",
        "    output = torch.softmax(logits / T, dim=1)\n",
        "\n",
        "    return logits, output"
      ],
      "metadata": {
        "id": "vwYAOkLnrau_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download trained weights of the Resnet18 model on CIFAR10 dataset\n",
        "!gdown 1KU4jWAwZIq0TUujAsgimLxGWUvwIEfyB"
      ],
      "metadata": {
        "id": "BvteE-DDJl8L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9cdc6b3-1397-446c-f328-e97cc1942ddb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1KU4jWAwZIq0TUujAsgimLxGWUvwIEfyB\n",
            "From (redirected): https://drive.google.com/uc?id=1KU4jWAwZIq0TUujAsgimLxGWUvwIEfyB&confirm=t&uuid=3c0fc021-2959-4141-8939-558c8a53f7fd\n",
            "To: /content/resnet18_cifar10_model_pretrained.pth\n",
            "100% 44.8M/44.8M [00:01<00:00, 32.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load trained Resnet18 model on CIFAR10 dataset\n",
        "model = resnet(len(classes)).to(device)\n",
        "model_name = \"resnet18_cifar10_model_pretrained.pth\"\n",
        "model_PATH = \"/content/\" + model_name\n",
        "state_dict = torch.load(model_PATH, map_location=device)\n",
        "model.load_state_dict(state_dict)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "An3EFVR2maw1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Computing clean accuracy"
      ],
      "metadata": {
        "id": "aPFQOzCXdm-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def standard_test(model, loader, device=device):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  ########################## Problem 2 (4 points) ##############################\n",
        "  # todo: Iterate over loader, compute the output and predicted                #\n",
        "  # label, and update \"correct\" and \"total\" counters accordingly.              #\n",
        "  ##############################################################################\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data in loader:\n",
        "      images, labels = data\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      output = model(images)\n",
        "      # Check if the model returns a tuple or a single tensor\n",
        "      if isinstance(output, tuple):\n",
        "        outputs, _ = output  # Unpack if the output is a tuple\n",
        "      else:\n",
        "        outputs = output  # Directly use the output if it's a tensor\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "  ################################ End #########################################\n",
        "  print(f'\\n Clean accuracy of the network on the 10000 test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "id": "mHw1Z4KJduA9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "standard_test(model, test_loader)"
      ],
      "metadata": {
        "id": "xiDPVF5BeI_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9807e029-3bd4-4cc3-da9f-09c191762427"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Clean accuracy of the network on the 10000 test images: 75 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C&W L2 Attack on the base model"
      ],
      "metadata": {
        "id": "ilLld2KN-UXG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that for the sake of simplicity, you can ignore binary search for constant c for your implementation. However, implementing it would earn you a bonus!"
      ],
      "metadata": {
        "id": "PiqsxXynerAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch.nn.functional as F\n",
        "def cw_l2_attack(model, image, label, mode='outputs', targeted=False, c=1e-4, kappa=0, max_iter=1000, learning_rate=0.01):\n",
        "\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "    ######################### Problem 3 (8 points) #############################\n",
        "    # todo: Implement L2 C&W attack in the two following modes:                #\n",
        "    # 'outputs': use an f function which utilizes output probs of the model    #\n",
        "    # 'logits': use an f function which utilizes logits of the model           #\n",
        "    # Output of this function must be the resulting adversarial image.         #\n",
        "    ############################################################################\n",
        "\n",
        "    # Setup the initial perturbation\n",
        "    w = torch.zeros_like(image).to(device)\n",
        "    w.requires_grad = True\n",
        "\n",
        "    # Setup optimizer\n",
        "    optimizer = optim.Adam([w], lr=learning_rate)\n",
        "\n",
        "    # Define the original image variable for perturbation adjustment\n",
        "    new_img = torch.tanh(w + image) / 2  # This squashes the w + image into the [0,1] range\n",
        "\n",
        "    for i in range(max_iter):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Generate adversarial image\n",
        "        adv_img = torch.tanh(w + image) / 2  # Ensure the adversarial image is within valid range\n",
        "\n",
        "        # Pass the adversarial image through the model\n",
        "        outputs = model(adv_img)\n",
        "\n",
        "        if mode == 'outputs':\n",
        "            # Use softmax probabilities\n",
        "            outputs = F.softmax(outputs, dim=1)\n",
        "        # If mode is 'logits', outputs are already logits\n",
        "\n",
        "        # Calculate the f-function\n",
        "        real = torch.max(outputs * label, dim=1)[0]  # Correct class probability or logit\n",
        "        other = torch.max((1 - label) * outputs - label * 10000, dim=1)[0]  # Max non-target class prob or logit\n",
        "\n",
        "        if targeted:\n",
        "            # If targeted, try to make the target class most likely\n",
        "            f = torch.clamp(other - real + kappa, min=0)\n",
        "        else:\n",
        "            # If untargeted, try to make the correct class less likely\n",
        "            f = torch.clamp(real - other + kappa, min=0)\n",
        "\n",
        "        # Calculate the CW loss\n",
        "        loss = torch.sum(f) + c * torch.sum(torch.pow(w, 2))  # L2 loss term to ensure minimal perturbation\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Early stopping if achieved required confidence\n",
        "        if f.item() < 1e-6:\n",
        "            break\n",
        "\n",
        "    # Create final adversarial image\n",
        "    adv_img = torch.tanh(w + image) / 2\n",
        "\n",
        "    return adv_img\n",
        "\n",
        "\n",
        "    ################################ End #######################################"
      ],
      "metadata": {
        "id": "D6iOQ5i4fHvO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def attack_test(model, attack_model, loader, mode='outputs', targeted=False, c=0.1,  device=device):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  ########################## Problem 4 (4 points) ##############################\n",
        "  # todo: Iterate over the FIRST batch of the loader                           #\n",
        "  # todo: Find an adversarial example by L2 C&W attack on attack_model         #\n",
        "  # todo: Compute the output and predicted label, and updated \"correct\" and    #\n",
        "  # \"total\" counters accordingly.                                              #\n",
        "  ##############################################################################\n",
        "  # Ensure the model is in evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  # Iterate only over the first batch of the DataLoader\n",
        "  first_batch = next(iter(loader))\n",
        "  images, labels = first_batch\n",
        "  images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "  for i in range(images.size(0)):\n",
        "    # Generate adversarial example using the C&W L2 attack\n",
        "    adv_image = cw_l2_attack(attack_model, images[i].unsqueeze(0), labels[i].unsqueeze(0), mode=mode, targeted=targeted, c=c)\n",
        "\n",
        "    # Pass the adversarial image through the model\n",
        "    output = model(adv_image)\n",
        "    if isinstance(outputs, tuple):\n",
        "      outputs = outputs[0]\n",
        "\n",
        "    if mode == 'outputs':\n",
        "      outputs = torch.softmax(outputs, dim=1)\n",
        "\n",
        "    # Calculate the predicted label\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "    # Update correct and total counters\n",
        "    total += labels[i].size(0)\n",
        "    correct += (predicted == labels[i]).sum().item()\n",
        "  ################################ End #########################################\n",
        "  print(f'\\n Accuracy of the network on the 64 test images of the first batch of testloader after attacking : {100 * correct // total} %')"
      ],
      "metadata": {
        "id": "pZ2pE6OxjIyy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print('C&W L2 attack on the model using its outpus(probs):')\n",
        "# attack_test(model, model, test_loader, mode='outputs', device=device)\n"
      ],
      "metadata": {
        "id": "IKF-S5Jklg_O"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# print('\\n C&W L2 attack on the model using its logits:')\n",
        "# attack_test(model, model, test_loader, mode='logits', device=device)"
      ],
      "metadata": {
        "id": "KvLg0W3BC4Dp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defensive distillation"
      ],
      "metadata": {
        "id": "XYpqaCNwj8X6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teacher model training"
      ],
      "metadata": {
        "id": "TXso9K0DnLrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/NightMachinery/PyNight.git\n",
        "!pip install --no-deps --force-reinstall git+https://github.com/NightMachinery/PyNight.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcC3_oVecaJA",
        "outputId": "6b83766c-1a9c-4abf-985d-46c226c34866"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/NightMachinery/PyNight.git\n",
            "  Cloning https://github.com/NightMachinery/PyNight.git to /tmp/pip-req-build-b7xxpbwt\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/NightMachinery/PyNight.git /tmp/pip-req-build-b7xxpbwt\n",
            "  Resolved https://github.com/NightMachinery/PyNight.git to commit 209dc31f78405e1f15e77546a794a8e1e1c97689\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aiofile (from pynight==0.2.2.1)\n",
            "  Downloading aiofile-3.8.8-py3-none-any.whl (19 kB)\n",
            "Collecting brish<0.4.0,>=0.3.3 (from pynight==0.2.2.1)\n",
            "  Downloading brish-0.3.4.5-py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.8/219.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython<3.0.0,>=2.1.0 (from pynight==0.2.2.1)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting executing<2.0.0,>=1.2.0 (from pynight==0.2.2.1)\n",
            "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from pynight==0.2.2.1) (3.7.1)\n",
            "Collecting openai<2.0.0,>=1.14.2 (from pynight==0.2.2.1)\n",
            "  Downloading openai-1.28.1-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyperclip<2.0.0,>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from pynight==0.2.2.1) (1.8.2)\n",
            "Requirement already satisfied: spacy<4.0.0,>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from pynight==0.2.2.1) (3.7.4)\n",
            "Collecting tiktoken<0.7,>=0.6 (from pynight==0.2.2.1)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting icecream<3.0.0,>=2.1.0 (from brish<0.4.0,>=0.3.3->pynight==0.2.2.1)\n",
            "  Downloading icecream-2.1.3-py2.py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pynight==0.2.2.1) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pynight==0.2.2.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pynight==0.2.2.1) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pynight==0.2.2.1) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pynight==0.2.2.1) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pynight==0.2.2.1) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pynight==0.2.2.1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pynight==0.2.2.1) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pynight==0.2.2.1) (2.8.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.14.2->pynight==0.2.2.1) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.14.2->pynight==0.2.2.1) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.14.2->pynight==0.2.2.1)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.14.2->pynight==0.2.2.1) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.14.2->pynight==0.2.2.1) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.14.2->pynight==0.2.2.1) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.14.2->pynight==0.2.2.1) (4.11.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (6.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (2.31.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (3.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.7,>=0.6->pynight==0.2.2.1) (2023.12.25)\n",
            "Collecting caio~=0.9.0 (from aiofile->pynight==0.2.2.1)\n",
            "  Downloading caio-0.9.13-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.14.2->pynight==0.2.2.1) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.14.2->pynight==0.2.2.1) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.14.2->pynight==0.2.2.1) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.14.2->pynight==0.2.2.1)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.14.2->pynight==0.2.2.1)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama>=0.3.9 (from icecream<3.0.0,>=2.1.0->brish<0.4.0,>=0.3.3->pynight==0.2.2.1)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from icecream<3.0.0,>=2.1.0->brish<0.4.0,>=0.3.3->pynight==0.2.2.1) (2.16.1)\n",
            "Collecting asttokens>=2.0.1 (from icecream<3.0.0,>=2.1.0->brish<0.4.0,>=0.3.3->pynight==0.2.2.1)\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai<2.0.0,>=1.14.2->pynight==0.2.2.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai<2.0.0,>=1.14.2->pynight==0.2.2.1) (2.18.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.7.1->pynight==0.2.2.1) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (2.0.7)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.5.1->pynight==0.2.2.1) (1.1.1)\n",
            "Building wheels for collected packages: pynight\n",
            "  Building wheel for pynight (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynight: filename=pynight-0.2.2.1-py3-none-any.whl size=74680 sha256=e17e64936e73460e32ee4dc5224969510c477d6e5ef51ef5be54217fc06028ee\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hw0jd4q6/wheels/8b/9f/a4/e339caf409dd92e03dc724ba2ac513deea53486ae149e7b597\n",
            "Successfully built pynight\n",
            "Installing collected packages: executing, h11, dnspython, colorama, caio, asttokens, tiktoken, icecream, httpcore, aiofile, httpx, brish, openai, pynight\n",
            "Successfully installed aiofile-3.8.8 asttokens-2.4.1 brish-0.3.4.5 caio-0.9.13 colorama-0.4.6 dnspython-2.6.1 executing-1.2.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 icecream-2.1.3 openai-1.28.1 pynight-0.2.2.1 tiktoken-0.6.0\n",
            "Collecting git+https://github.com/NightMachinery/PyNight.git\n",
            "  Cloning https://github.com/NightMachinery/PyNight.git to /tmp/pip-req-build-r15p77ve\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/NightMachinery/PyNight.git /tmp/pip-req-build-r15p77ve\n",
            "  Resolved https://github.com/NightMachinery/PyNight.git to commit 209dc31f78405e1f15e77546a794a8e1e1c97689\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pynight\n",
            "  Building wheel for pynight (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynight: filename=pynight-0.2.2.1-py3-none-any.whl size=74680 sha256=e17e64936e73460e32ee4dc5224969510c477d6e5ef51ef5be54217fc06028ee\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-611ig2n2/wheels/8b/9f/a4/e339caf409dd92e03dc724ba2ac513deea53486ae149e7b597\n",
            "Successfully built pynight\n",
            "Installing collected packages: pynight\n",
            "  Attempting uninstall: pynight\n",
            "    Found existing installation: pynight 0.2.2.1\n",
            "    Uninstalling pynight-0.2.2.1:\n",
            "      Successfully uninstalled pynight-0.2.2.1\n",
            "Successfully installed pynight-0.2.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pynight.common_torch import (\n",
        "    img_tensor_show,\n",
        "    TorchModelMode,\n",
        "    model_device_get,\n",
        "    torch_shape_get,\n",
        ")"
      ],
      "metadata": {
        "id": "uO8NAjLfcN0h"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "def evaluate(model, testloader, prefix=\"\"):\n",
        "    with TorchModelMode(model, 'eval'):\n",
        "        device = model_device_get(model)\n",
        "\n",
        "        predictions = []\n",
        "        labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data in testloader:\n",
        "                inputs, targets = data\n",
        "                inputs = inputs.to(device)\n",
        "                targets = targets.to(device)\n",
        "\n",
        "                res = model(inputs)\n",
        "                _, predicted = torch.max(res.logits.data, 1)\n",
        "\n",
        "                predictions.extend(predicted.cpu().numpy())\n",
        "                labels.extend(targets.cpu().numpy())\n",
        "\n",
        "        accuracy = accuracy_score(labels, predictions)\n",
        "\n",
        "        f1 = f1_score(labels, predictions, average='weighted')\n",
        "        print('{}Accuracy: {:.2f}%, F1 Score: {:.2f}'.format(prefix, accuracy * 100, f1))\n"
      ],
      "metadata": {
        "id": "rGRZeYPvbCeT"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standard_train(\n",
        "    model, loader, num_epoch, optimizer, criterion, T=None, device=device\n",
        "):\n",
        "    ###################### Problem 2 (4 points) ##################################\n",
        "    # todo: Iterate over loader in each epoch                                    #\n",
        "    # todo: Compute the model's output for each batch at the given temperature T #\n",
        "    # todo: Compute the loss function and take a step by the optimizer           #\n",
        "    # todo: Monitor the training procedure                                       #\n",
        "    ##############################################################################\n",
        "\n",
        "    evaluate(model=model, testloader=test_loader, prefix=\"before training: \")\n",
        "\n",
        "    for epoch in range(1, num_epoch + 1):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(loader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            res = model(inputs, T=T)\n",
        "\n",
        "            loss = criterion(res.logits_scaled, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch}, Loss: {running_loss / len(loader)}\")\n",
        "\n",
        "        if epoch % 5 == 0:\n",
        "            evaluate(model=model, testloader=test_loader, prefix=f\"Epoch {epoch}: \")"
      ],
      "metadata": {
        "id": "WDc56vcNZ8pN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T = 100\n",
        "teacher = resnet(len(classes), T=T).to(device)\n",
        "teacher_optim = optim.Adam(teacher.parameters())\n",
        "teacher_criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "T1eUl9f4j_Mt"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # load teacher model (if you already trained it)\n",
        "# model_name = \"teacherModel.pth\"\n",
        "# teacher_model_PATH = \"/content/drive/MyDrive/\" + model_name\n",
        "# state_dict = torch.load(teacher_model_PATH)\n",
        "# teacher.load_state_dict(state_dict)\n",
        "# teacher = teacher.to(device)"
      ],
      "metadata": {
        "id": "NyV1KEBDkayQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "standard_train(model=teacher,\n",
        "            loader=train_loader,\n",
        "            num_epoch=15,\n",
        "            optimizer=teacher_optim,\n",
        "            criterion=teacher_criterion,\n",
        "            device=device)"
      ],
      "metadata": {
        "id": "S7p5sKb8kjXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save teacher model (only if you just trained it)\n",
        "teacher.eval()\n",
        "model_name = \"teacherModel.pth\"\n",
        "teacher_model_PATH = \"/content/drive/MyDrive/\" + model_name\n",
        "torch.save(teacher.state_dict(), teacher_model_PATH)"
      ],
      "metadata": {
        "id": "TaNnzhvbm4_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Student model training"
      ],
      "metadata": {
        "id": "yetQZRHYnPJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def distillation(teacher, student, loader, num_epoch, optimizer, criterion, device=device):\n",
        "  ########################## Problem 5 (6 points) ##############################\n",
        "  # todo: Iterate over loader in each epoch                                    #\n",
        "  # todo: Compute MSE loss between student's logit and teacher's logit         #\n",
        "  # todo: Take a step by the optimizer                                         #\n",
        "  # todo: Monitor the training procedure                                       #\n",
        "  ##############################################################################\n",
        "  evaluate(model=student, testloader=testloader, prefix=\"before training: \")\n",
        "  for epoch in range(1, num_epoch + 1):\n",
        "      running_loss = 0.0\n",
        "      for i, data in enumerate(loader, 0):\n",
        "          inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          res = student(inputs, T=T)\n",
        "\n",
        "          with torch.no_grad():\n",
        "              teacher_res = teacher(inputs, T=T)\n",
        "              if mode == 'logits':\n",
        "                  teacher_labels = teacher_res.logits_scaled\n",
        "              else:\n",
        "                  teacher_labels = teacher_res.output\n",
        "\n",
        "          loss = criterion(res.logits_scaled, teacher_labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          running_loss += loss.item()\n",
        "\n",
        "      print(f\"Epoch {epoch}, Loss: {running_loss / len(loader)}\")\n",
        "\n",
        "      if epoch % 5 == 0:\n",
        "          evaluate(model=student, testloader=testloader, prefix=f\"Epoch {epoch}: \")\n",
        "  ################################ End #########################################"
      ],
      "metadata": {
        "id": "9t69EQ9WnQpF"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T = 100\n",
        "student = resnet(len(classes), T=T).to(device)\n",
        "student_optim = optim.Adam(student.parameters())\n",
        "std_criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "ma5j_YhhnlF-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load student model (only if you already trained it)\n",
        "model_name = \"studentModel.pth\"\n",
        "student_model_PATH = \"/content/drive/MyDrive/\" + model_name\n",
        "state_dict = torch.load(student_model_PATH)\n",
        "student.load_state_dict(state_dict)\n",
        "student = student.to(device)"
      ],
      "metadata": {
        "id": "UTUUWY8fnmi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distillation(teacher=teacher,\n",
        "             student=student,\n",
        "             loader=train_loader,\n",
        "             num_epoch=15,\n",
        "             optimizer=student_optim,\n",
        "             criterion=std_criterion,\n",
        "             device=device)"
      ],
      "metadata": {
        "id": "KDo7FSYAnzmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save student model (only if you just trained it)\n",
        "student.eval()\n",
        "model_name = \"studentModel.pth\"\n",
        "teacher_model_PATH = \"/content/drive/MyDrive/\" + model_name\n",
        "torch.save(student.state_dict(), teacher_model_PATH)"
      ],
      "metadata": {
        "id": "7KK0cjx6n5LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C&W L2 Attack on the distilled  model"
      ],
      "metadata": {
        "id": "cB8T-Dq2pu9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('C&W L2 attack on the student model using its outpus(probs):')\n",
        "attack_test(student, student, test_loader, mode='outputs', device=device)\n",
        "\n",
        "print('\\n C&W L2 attack on the student model using its logits:')\n",
        "attack_test(student, student, test_loader, mode='logits', device=device)"
      ],
      "metadata": {
        "id": "6F9opcKwpHvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyzing the results"
      ],
      "metadata": {
        "id": "ge7pcN_sNBul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer the following questions below them: (6 points)\n",
        "\n",
        "1. Why do you think the attack success rate of the logits mode is generally better than the outputs(probs) mode?\n",
        "#1. Direct Access to Model Decision Boundaries\n",
        "#2. Gradient Sensitivity and Saturation\n",
        "#3. Effectiveness in Targeting Specific Outcomes\n",
        "#4. Optimization Stability\n",
        "\n",
        "#######################################################################################\n",
        "\n",
        "\n",
        "2. Why defensive distillation completely failed in the logits mode?\n",
        "\n",
        "fails in logits mode because logits are unbounded and provide more gradient information. This allows attackers to exploit larger gradient signals for crafting adversarial examples, bypassing the distillation's intended effect of smoothing out model responses\n",
        "\n",
        "\n",
        "#######################################################################################\n",
        "3. As you have seen, defensive distillation is a mirage. Do you think that there is still some scenarios that this defense may be helpful?\n",
        "\n",
        "t can enhance model generalization and defend against simpler attacks like FGSM by smoothing model outputs and reducing sensitivity to small input variations. Distillation may also improve model performance on noisy or slightly perturbed data, acting as a form of regularization.\n",
        "\n"
      ],
      "metadata": {
        "id": "lsudexRmNZll"
      }
    }
  ]
}