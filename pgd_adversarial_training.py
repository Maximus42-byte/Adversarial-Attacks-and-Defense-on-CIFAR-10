# -*- coding: utf-8 -*-
"""PGD_Adversarial_Training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GPZynphuSxCLBrY6427AR3N9vsCFDR-x

<center>
<h1>In the name of Allah</h1>
</center>

**Name: Mahdi Saieedi**


**Student Number:401207254**
"""

from google.colab import drive
drive.mount('/content/drive')

# !pip uninstall torch torchvision
# !pip install torch torchvision

import torch
import torchvision
import torchvision.transforms as transforms
from torchvision.models import resnet18
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import numpy as np
from torch.autograd import Variable
from tqdm import tqdm

"""# A. Load the pretrained Resnet on CIFAR10"""

transform = transforms.Compose([transforms.ToTensor()])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=transform)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform)

batch_size = 128

########################## Problem 0 (0  points) ###############################
# todo: Define your data loaders for training and testing                      #
################################################################################

# your code goes here

from torch.utils.data import DataLoader

# Define your data loaders for training and testing
train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)
test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)

################################ End ###########################################


################################ End ###########################################

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

class resnet(nn.Module):
  def __init__(self, num_cls, T=1):
    super().__init__()
    self.conv = nn.Sequential(
        *list(resnet18(weights=None).children())[:-2])

    self.fc = nn.Linear(512, num_cls)
    self.temp = T

  def forward(self, x, T=None):
    if T is None:
      T = self.temp
    x = self.conv(x)
    x = torch.flatten(x, start_dim=1)
    logits = self.fc(x)
    output = torch.softmax(logits / T, dim=1)

    return logits, output

# Download trained weights of the Resnet18 model on CIFAR10 dataset
!gdown 1KU4jWAwZIq0TUujAsgimLxGWUvwIEfyB

# load trained Resnet18 model on CIFAR10 dataset
model = resnet(len(classes)).to(device)
model_name = "resnet18_cifar10_model_pretrained.pth"
model_PATH = "/content/" + model_name
state_dict = torch.load(model_PATH, map_location=device)
model.load_state_dict(state_dict)
model = model.to(device)

# def model_normalized(model, inputs):
#     return model(transform_normalize(inputs))

next(model.parameters()).device

next(model.parameters()).is_cuda

# pip install --upgrade torch

# transform_normalize = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))

# def model_normalized(model, inputs):
#     return model(transform_normalize(inputs))

def standard_test(model, loader, device=device):
  correct = 0
  total = 0
  ########################## Problem 0 (0 points) ##############################
  # todo: Iterate over loader, compute the output and predicted                #
  # label, and update "correct" and "total" counters accordingly.              #
  ##############################################################################

  # Set the model to evaluation mode
  model.eval()

  with torch.no_grad():
    for data in loader:
      images, labels = data
      images = images.to(device)
      labels = labels.to(device)
      output = model(images)
      # Check if the model returns a tuple or a single tensor
      if isinstance(output, tuple):
        outputs, _ = output  # Unpack if the output is a tuple
      else:
        outputs = output  # Directly use the output if it's a tensor

      _, predicted = torch.max(outputs.data, 1)
      total += labels.size(0)
      correct += (predicted == labels).sum().item()
  ################################ End #########################################
  print(f'\n Clean accuracy of the network on the 10000 test images: {100 * correct // total} %')

standard_test(model=model, loader= test_loader)

standard_test(model=model, loader= train_loader)

"""# B. PGD Attack"""

# Implement PGD attack

class LinfPGDAttack(object):

    def __init__(self, model, epsilon = 8/255, k = 2, alpha = 2/255):
        self.model = model
        self.epsilon = epsilon
        self.steps = k
        self.alpha = alpha

    def __call__(self, image, label):
        image = image.to(device)
        label = label.to(device)
        outs= self.model(image)
        if isinstance(outs, tuple):
          out, _ = outs  # Unpack if the output is a tuple
        else:
          out = outs
        _, pred = torch.max(out, 1)
        perturbed_image = image.clone()
        perturbed_image.to(device)
        #if pred.item() == label.item():
            ########################## Problem 1 (8 points) ##############################
            # Implement a k step PGD attack of size alpha                                #
            # while always staying within epsilon distance from the initial point        #
            # Use cross entropy loss                                                     #
            ##############################################################################
        loss = nn.CrossEntropyLoss()
        ori_image = image.data
        for i in range(self.steps):
          image.requires_grad = True
          outs = self.model(image)
          if isinstance(outs, tuple):
            out, _ = outs  # Unpack if the output is a tuple
          else:
            out = outs
          self.model.zero_grad()
          cost = loss(out, label).to(device)
          cost.backward()
          adv_image = image + self.alpha*image.grad.sign()
          eta = torch.clamp(adv_image - ori_image, min=-1*self.epsilon, max=self.epsilon)
          image = torch.clamp(ori_image + eta, min=0, max=1).detach_()

        perturbed_image=image



            ################################ End #########################################

        return perturbed_image

def evalute_pgd(model_input, k_input):
  correct = 0
  total = 0
  model_input.eval()
  pgd = LinfPGDAttack(model_input,k=k_input)
  for data in tqdm(test_loader):
    images, labels = data
    images = images.to(device)
    labels = labels.to(device)
    adv=pgd(images,labels)
    adv_output = model_input(adv)
    if isinstance(adv_output, tuple):
        adv_outputs, _ = adv_output  # Unpack if the output is a tuple
    else:
        adv_outputs = adv_output  # Directly use the output if it's a tensor
    # print(adv_outputs.size())
    _, predicted = torch.max(adv_outputs.data, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()
  print(f'adversarial Accuracy of new model against pgd attack on the 10000 test images with 8/255 and k={k_input} : {100 * correct / total} %')

evalute_pgd(model_input = model, k_input = 2)

########################## Problem 2 (4 points) ##############################
# Evaluate PGD attack on the trained model with k=2,4,8                      #
##############################################################################

k_list = [2,4,8]

##############################################################################


for _k in k_list:
  evalute_pgd(model_input = model  , k_input = _k)



################################ End #########################################

########################## Problem 3 (4 points) ##############################
# Choose 3 images from the test set that have been incorrectly classified    #
# and plot the actual image, the added noise, and the perturbed image        #
##############################################################################


##############################################################################
import matplotlib.pyplot as plt
model=model.to(device)
newset=torch.utils.data.DataLoader(testset, batch_size = len(testset), shuffle = False, num_workers = 2)
for d,l in newset:
  data=d.to(device)
  targets=l.to(device)

a=[]
model.eval()
pgd=LinfPGDAttack(model,k=4)
for i in tqdm(range(3)):
  adv=pgd(data[i:i+1],targets[i:i+1])
  _,adv_predicted=torch.max(model(adv)[0].data, 1)
  _,true_predicted=torch.max(model(data[i:i+1])[0].data, 1)
  a.append((adv,data[i],adv_predicted[0],true_predicted[0]))


for i in range(3):
  print('the true label is : '+str(a[i][3].item())+' and the model prediction is : '+str(a[i][2].item()))

fig = plt.figure()
fig.set_figheight(12)
fig.set_figwidth(12)
for i in range(3):
  adversary_image=np.transpose(a[i][0].detach().cpu().numpy()[0],(1,2,0))
  original_image=np.transpose(a[i][1].detach().cpu().numpy(),(1,2,0))
  plt.subplot(5,3,i*3+1)
  plt.title(classes[a[i][3].item()])
  plt.axis('off')
  plt.imshow(original_image)
  plt.subplot(5,3,i*3+2)
  plt.title('noise')
  plt.axis('off')
  noise=adversary_image-original_image
  plt.imshow(noise/(2*(noise.max()-noise.min()))+0.5)
  plt.subplot(5,3,i*3+3)
  plt.title(classes[a[i][2].item()])
  plt.axis('off')
  plt.imshow(adversary_image)


################################ End #########################################

"""# C. FGSM Attack"""

class FGSMAttack():

    def __init__(self, model):
        self.model = model
        self.adversarials = []
        self.originals = []
        self.predictions = []
        self.confidences = []
        self.truths = []



    def untargeted_fgsm(self, image, epsilon, gradient):

      # Define untargeted fast gradient sign attack pertubation
      # Firstly perturb the image in the proper direction then clamp it between the right values.
      #############################
      # Your code goes here

      sign_data_grad = gradient.sign()

      perturbed_image = image + epsilon*sign_data_grad

      perturbed_image = torch.clamp(perturbed_image, 0, 1)

      return perturbed_image
      #############################

    def __call__(self, image, label, epsilon):


      image = image.to(device)
      label = label.to(device)

      true_image = image.clone()
      image.requires_grad = True
      outs= self.model(image)
      if isinstance(outs, tuple):
        out, _ = outs  # Unpack if the output is a tuple
      else:
        out = outs
      _, pred = torch.max(out, 1)



        # image.requires_grad = True

        # Now define a loss(use the negative log likelihood loss),
        # Zero the gradients of the model parameters and do the backpropagation
        # Retrieve the gradient of the loss with respect to the input image
        # Finally use the function you defined earlier to craft the perturbed image
        #############################
        # Your code goes here
      loss = F.nll_loss(out, label)
      self.model.zero_grad()

      loss.backward()
      image_grad = image.grad.data

      perturbed_image = self.untargeted_fgsm(image, epsilon, image_grad)

      #############################

      outs2 = self.model(perturbed_image)
      if isinstance(outs2, tuple):
        out2, _ = outs2  # Unpack if the output is a tuple
      else:
        out2 = outs2

      _, pred2 = torch.max(out2.data, 1)

      confidence = F.softmax(out2, dim=1)[0][pred2].data

      prob = confidence

      # self.adversarials.append(perturbed_image.squeeze().detach().cpu().numpy())
      # self.originals.append(true_image.squeeze().detach().cpu().numpy())
      # self.predictions.append(pred2.item())
      # self.confidences.append(confidence.item())
      # self.truths.append(label.item())


      return perturbed_image, pred2, confidence, label

########################## Problem 4 (2 points) ##############################
# Use your implementation from last HW for untargeted FGSM attack            #
##############################################################################

# Your code goes here
#implemented in the last block

################################ End #########################################

def fgsm_eval(model , epsilon):
  fgsmattack=FGSMAttack(model)
  model.eval()
  correct = 0
  total = 0
  for data in tqdm(test_loader):
      images, labels = data
      images = images.to(device)
      labels = labels.to(device)
      adv,adv_outputs,_,_=fgsmattack(images,labels,epsilon)
      # outputs = model(images)
      predicted =adv_outputs
      total += labels.size(0)
      correct += (predicted == labels).sum().item()

  print(f'adversarial Accuracy of ResNet18 model on the 10000 test images with {epsilon} : {100 * correct / total} %')

########################### Problem 5 (2 points) #############################
# Evaluate untargeted FGSM attack on the trained model with epsilon = 8/255  #
##############################################################################

fgsm_eval(model , 8/255)
################################ End #########################################

"""# D. Adversarial Training"""

########################### Problem 6 (1 points) #############################
# Load a new resnet model for adversarial training                           #
##############################################################################

# Your code goes here

adv_model = resnet18(pretrained=True)

################################ End #########################################

adv_model = adv_model.to(device)
adv_model.train()

########################### Problem 6 (6 points) #############################
# Train the model on perturbed images from                                   #
# untargeted FGSM attack with epsilon = 8/255 on train dataset               #
# Also use the following setup for training the model                        #
##############################################################################

learning_rate = 0.01
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)
epochs = 5

##############################################################################

# Your code goes here
fgsmattack=FGSMAttack(model)
for epoch in range(epochs):
    print("epoch " + str(epoch))
    running_loss = 0.0
    for i, data in tqdm(enumerate(train_loader,0)):

        inputs, labels = data[0].to(device), data[1].to(device)
        optimizer.zero_grad()
        # outputs = adversary_model(inputs)
        adv,adv_outputs,_,_=fgsmattack(inputs,labels,8/255)
        adv_outputs=adv_model(adv)
        loss = criterion(adv_outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 380 == 1:    # print every 2000 mini-batches #1999
            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss/380 :.10f}')
            running_loss = 0.0


print('Finished Training')


################################ End #########################################

# save adversary model
adv_model.eval()
model_name = "adversary-resnet18_cifar10_model_std"
CIFAR10_model_PATH = "/content/drive/MyDrive/" + model_name
torch.save(adv_model.state_dict(), CIFAR10_model_PATH)

# load the adversary model
model_name = "adversary-resnet18_cifar10_model_std"
CIFAR10_model_PATH = "/content/drive/MyDrive/" + model_name
adversary_model = resnet18()
adversary_model.load_state_dict(torch.load(CIFAR10_model_PATH))
adversary_model.eval()
adversary_model = adversary_model.to(device)

########################### Problem 7 (2 points) #############################
# Evaluate the new model on the test dataset                                 #
##############################################################################
standard_test(adv_model, loader= test_loader)
################################ End #########################################

########################### Problem 8 (3 points) #############################
#  Run PGD attack on the adversarially trained model with k=2,4,8            #
##############################################################################

k_list = [2,4,8]
for _k in k_list:
  evalute_pgd(model_input = adv_model  , k_input = _k)

##############################################################################

# Your code goes here

################################ End #########################################

########################### Problem 9 (1 points) #############################
# Run FGSM attack on the adversarially trained model with epsilon = 8/255    #
##############################################################################
fgsm_eval(adv_model , 8/255)
################################ End #########################################

"""# E. Analyze Results (5 points)

- Analyze the results for the 3 above cells

Your Answer

# F. Built-In Libraries

Use the following library and run FGSM and PGD attack for CIFAR10 test dataset on the given model and compare the results with your own results


https://adversarial-attacks-pytorch.readthedocs.io/en/latest/index.html
"""

!pip install torchattacks

########################### Problem 10 (12 points) #############################
# Run FGSM attack (using library) on the pretrained model for the test dataset #
# Run PGD attack (using library) on the pretrained model for the test dataset  #
################################################################################
import torchattacks

################################ End #########################################

import torchvision.models as models
model2 = models.resnet18(pretrained=True).eval()
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model2 = model2.to(device)

fgsm_attack = torchattacks.FGSM(model2, eps=8/255)

def evaluate_attack(attack):
    correct = 0
    total = 0
    for images, labels in test_loader:
        images = images.to(device)
        labels = labels.to(device)

        # Generate adversarial examples
        adv_images = attack(images, labels)

        outputs = model2(adv_images)
        if isinstance(outputs, tuple):  # Check if output is a tuple and extract the logits
            outputs = outputs[0]

        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    print(f'Accuracy after attack: {100 * correct / total:.2f}%')

evaluate_attack(fgsm_attack)

pgd_attack = torchattacks.PGD(model2, eps=0.03, alpha=0.01, steps=40)  # Configure the PGD attack

evaluate_attack(pgd_attack)

